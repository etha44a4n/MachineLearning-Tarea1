{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c749e32c",
   "metadata": {},
   "source": [
    "# Aprendizaje de Máquina\n",
    "## Tarea 1: clasificación y regresión en vinos\n",
    "__Descripción:__ En este trabajo realizaremos un modelo de aprendizaje automatizado, para predecir la puntuación de calidad de un vino dependiendo de sus cualidades tales como acidez y azúcares, entre otros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898adbe7",
   "metadata": {},
   "source": [
    "## Implementación de librerias\n",
    "Importamos las librerias con las que vamos a trabajar en este notebook, entre las cuales podemos apreciar numpy para trata numérica, matplotlib para mostrar gráficas, pandas para trata de DataFrames, scikit-learn para los modelos de aprendizaje y ucimlrepo para importar el dataset de los vinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.utils import shuffle\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36f76c",
   "metadata": {},
   "source": [
    "## Importación del dataset\n",
    "Importamos el dataset de vinos con el que vamos a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bd841",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality = fetch_ucirepo(id=186)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafb34d",
   "metadata": {},
   "source": [
    "## Transformación del dataset a pandas DataFrame\n",
    "Transformamos el dataset a un DataFrame de pandas para despues poderlo procesar con la libreria scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50203255",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_df = pd.DataFrame(data=wine_quality.data.features, columns=wine_quality.data.feature_names)\n",
    "wq_df['quality'] = wine_quality.data.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a3bac",
   "metadata": {},
   "source": [
    "## Generación de datos sintéticos\n",
    "Generamos datos sintéticos con la finalidad de aumentar la cantidad de información con la que trabajarán los modelos, esperando obtener mejores resultados de esta manera.\n",
    "Copiamos 3503 datos del dataset original, para así llegar a un total de 10000 datos, a estos datos nuevos les añadimos un poco de ruido para generar variedad, este ruido no se añade a la columna objetivo de 'Calidad' ya que los datos originales son números enteros.\n",
    "Una vez generados los datos sintéticos los juntamos con los datos originales para obtener un solo DataFrame con el cuál trabajar por el resto del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = shuffle(wq_df)\n",
    "\n",
    "synthetic_data = shuffled_df.iloc[:3503].copy()\n",
    "\n",
    "for column in synthetic_data.select_dtypes(include=np.number):\n",
    "    if column == 'quality':\n",
    "        continue\n",
    "    synthetic_data[column] += np.random.normal(0, 0.1, len(synthetic_data))\n",
    "\n",
    "combined_data = pd.concat([wq_df, synthetic_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9a0c5",
   "metadata": {},
   "source": [
    "## Separación de datos de entrenamiento y validación\n",
    "Generamos dos DataFrames nuevos, uno que contiene todos los datos a excepción de los resultados (la columna de 'calidad'), y otro que solamente contiene los resultados, con este par de DataFrames generamos cuatro DataFrames más:\n",
    "1. __X_train:__ datos para entrenar los modelos\n",
    "1. __X_test:__ datos con los que los modelos no trabajan, con la finalidad de usarlos en la fase de evaluación\n",
    "1. __y_train:__ datos de resultados con los cuales los modelos aprenden a predecir en base a la información entregada previamente\n",
    "1. __y_test:__ datos de resultados con los cuales los modelos no se entrenan, con la finalidad de evaluar los resultados en la fase de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_data.drop('quality', axis=1)\n",
    "y = combined_data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa287b7",
   "metadata": {},
   "source": [
    "Una vez que tenemos todo lo necesario para entrenar a los modelos, procederemos con el entrenamiento para regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3eab5e",
   "metadata": {},
   "source": [
    "# Regresión\n",
    "La regresión para este caso consiste en generar una relación entre las características del vino, con los resultados, con la finalidad de predecir el mejor resultado posible cuando se entreguen nuevos datos.\n",
    "Si la clasificación original de una nueva entrada es 3, se entiende por mejor resultado de clasificación un 2 o un 4 que un 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3df91",
   "metadata": {},
   "source": [
    "## Definición de hiperparámetros para optimización\n",
    "Definimos una serie de hiperparámetros para un modelo de Support Vector Machine, con los cuales, se probaran todas las combinaciones posibles con la finalidad de encontrar la mejor combinación.\n",
    "Los hiperparámetros son:\n",
    "1. __kernel:__ el tipo de transformación kernel que se realizará para trabajar con múltiples dimensiones\n",
    "1. __C:__ el parámetro de regularización, mientras más grande sea el valor, más se penalizan los errores\n",
    "1. __gamma:__ coeficiente de kernel para poly, rbf y sigmoid\n",
    "1. __epsilon:__ la holgura que se le entrega al modelo para poder fallar\n",
    "1. __max_iter:__ la cantidad máxima de iteraciones que realizará el modelo, con esto evitamos que trabaje de manera indefinida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76648015",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'epsilon': [0.01, 0.1, 1],\n",
    "    'max_iter': [50, 100, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde091d",
   "metadata": {},
   "source": [
    "## Búsqueda de hiperparámetros\n",
    "Utilizamos la implementación de GridSearchCV entregada por la librería de scikit-learn.\n",
    "Esto realiza un entrenamiento con el modelo SVR (Support Vector Regression), probando cada combinación de los hiperparámetros definidos anteriormente, usando validación cruzada y buscando el mejor puntaje $r²$.\n",
    "Una vez terminado se puede obtener la mejor combinación de parámetros y guardar ese modelo sin necesidad de definirlo a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_svr = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537d357",
   "metadata": {},
   "source": [
    "## Métricas y predicciones\n",
    "Una vez obtenido la mejor versión de SVR para este caso, podemos ver las métricas tales como el error cuadrático medio, error absoluto medio y puntaje $r²$.\n",
    "Además podemos mostrar en un gráfico las predicciones realizadas por el modelo contra los verdaderos resultados de los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_best)}\")\n",
    "print(f\"MSE**0.5: {mean_squared_error(y_test, y_pred_best)**0.5}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_best)}\")\n",
    "print(f\"r2_score: {r2_score(y_test, y_pred_best)}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred_best)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title('Best SVR Model Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97834090",
   "metadata": {},
   "source": [
    "# Clasificación\n",
    "Los modelos de clasificación, como su nombre indica, clasifican los datos en clases, para este caso cada clase es la posible nota que reciba el vino, respecto a los resultados solo hay dos posibilidades, bien clasificado o mal clasificado.\n",
    "Procederemos a realizar el mismo procedimiento que realizamos para regresión, pero con el modelo que utilizaremos para clasificación.\n",
    "Debido a la similitud de los procesos solo se hablará de las diferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477067a6",
   "metadata": {},
   "source": [
    "## Definición de hiperparámetros\n",
    "El modelo SVC no utiliza epsilon y se puede entregar el valor random_state, que permite definir una semilla para controlar la generación de valores pseudo aleatorios, si no definimos este valor, en cada iteración que se realice se cambiarán ciertos valores llevando a una inconsistencia en el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f904a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 1, 10, 100], #Regularization\n",
    "    'gamma': ['scale', 'auto', 0.1, 1], #kernel coefficient for rbf, poly & sigmoid\n",
    "    'random_state': [42],\n",
    "    'max_iter': [50, 100, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebce43",
   "metadata": {},
   "source": [
    "## Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37404099",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_svc = grid_search.best_estimator_\n",
    "print(\"Best hyperparameters\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1b36d",
   "metadata": {},
   "source": [
    "## Métricas y predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_best)}\")\n",
    "print(f\"MSE**0.5: {mean_squared_error(y_test, y_pred_best)**0.5}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_best)}\")\n",
    "print(f\"r2_score: {r2_score(y_test, y_pred_best)}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred_best)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title('Best SVC Model Prediction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
